# Wrangling {#Wrangling}

```{r, include = FALSE}
# needed functions for scraping team data
## get team names
get_teams <- function(pfr_url){
  require(tidyverse)
  require(rvest)
  team_link <- str_c(pfr_url, '/teams/')
  team_link %>%
    read_html(.) %>%
    html_node(., css = '#teams_active') %>%
    html_nodes(., xpath = "//th[@data-stat='team_name']") %>%
    html_nodes(., css = 'a') %>%
    html_attr(., 'href')
}
## get player names
get_players <- function(team_url){
  require(janitor)
  require(tidyverse)
  require(rvest)
  pfr_url <- str_extract(team_url, "(.*?).com")
  team_url %>%
    read_html() %>%
    html_node(., css = '#all_rushing_and_receiving') %>%
    html_nodes(., xpath = 'comment()') %>%
    html_text() %>%
    read_html() %>%
    html_nodes(., 'table') %>%
    html_nodes(., 'a') %>%
    html_attr(., 'href') %>%
    str_c(pfr_url, .)
}
## get team statistics
get_team_conversions <- function(team_url){
  require(janitor)
  require(tidyverse)
  require(rvest)
  team_abbr <- str_sub(team_url, start = 46, end = 48)
  team_url %>%
    read_html(.) %>%
    html_node(., css = '#team_conversions') %>%
    html_table(.) %>%
    row_to_names(., row_number = 1) %>%
    clean_names() %>%
    mutate(., team = team_abbr) %>%
    select(., team, everything())
}
## get aggregated player statistics
get_team_stats <- function(team_url){
  require(janitor)
  require(tidyverse)
  require(rvest)
  team_abbr <- str_sub(team_url, start = 46, end = 48)
  team_url %>%
    read_html() %>%
    html_node(., css = '#all_rushing_and_receiving') %>%
    html_nodes(., xpath = 'comment()') %>%
    html_text() %>%
    read_html() %>%
    html_node(., 'table') %>%
    html_table() %>%
    set_names(., str_c(names(.), .[1,], sep = '_')) %>%
    clean_names() %>%
    slice(., -1) %>%
    rename_at(., vars(starts_with('total')), ~str_sub(.x, start = 7)) %>%
    rename(., rushing_fmb = fmb) %>%
    mutate(., team = team_abbr) %>%
    select(., team, no, player, age, pos, starts_with('games_'), starts_with('rushing_'),
           starts_with('receiving_'), starts_with('yds_'))
}
## get game by game player statistics
get_player_stats <- function(player_url){
  require(janitor)
  require(tidyverse)
  require(rvest)
  player_url %>%
    read_html() %>%
    html_node(., css = '#all_stats') %>%
    html_node(., 'table') %>%
    html_table(., fill = TRUE) %>%
    set_names(., str_c(names(.), .[1,], sep = '_')) %>%
    clean_names() %>%
    slice(., -1) %>%
    select(., team = tm, everything())
}
```

> "The work that you do with data wrangling others would call ‘data plumbing’ or even janitorial work, but when you have somebody who knows how to wrangle data and gets into a flow of data wrangling, it’s an elegant dance to watch." —Stephanie McReynolds, Strategic Adviser, Nexla

In Chapter \@ref(AccessingData), we introduced the idea of rectangular data vs. non-rectangular data, providing examples for each and demonstrating the process of rectangularization. We outlined how to use a web-API before a light introduction to web scraping. In this chapter, we will familiarize ourselves with data wrangling, the art of cleaning up our data.

Furthermore, in Chapter \@ref(AccessingData), we briefly touched on the notion of tidy data: data structures where observations are given by rows, variables are given by columns, and values are given by cells. The notion of tidy data was formalized by @wickham2014tidy, Chief Scientist at RStudio and creator of the Tidyverse universe, to reduce the amount of work involved in preparing data. Data preparation, or data cleaning, is often a time consuming task with real data. Since it's necessary to format data as tidy data to use the vast network of packages within the Tidyverse, we always need to first structure our data as tidy data.

```{r, fig.cap="visualizing tidy data", echo=F}
knitr::include_graphics("src/images/tidy_data.png")
```

In the following subsections, we will be cleaning up those data gathered from Pro Football Reference.

```{block, type='feedback'}
Any feedback for this section? Click [here](https://docs.google.com/forms/d/e/1FAIpQLSePQZ3lIaCIPo9J2owXImHZ_9wBEgTo21A0s-A1ty28u4yfvw/viewform?entry.1684471501=The%20R%20Community)
```

## Core Tidyverse

At the heart of Tidyverse are a few packages: `dplyr`, `tidyr`, `stringr`, and `forcats`. Each package serves a powerful purpose. `tidyr` helps you create tidy data, while `dplyr` is used for data manipulation. Think of `tidyr` as the crowbar or saw in your toolbox, allowing you to bend and shape your data into tidy shape. `dplyr`, on the other hand, is more like the screwdriver, hammer, or level, allowing you to fix pesky issues with the data. `stringr` and `forcats` are useful when working with strings and factors (categorical variables that have a fixed and known set of possible values).

While we will make the effort to teach `tidyr` and `dplyr` separately within their own subsections, we recognize that these packages are ultimately created to be used together. Since we may need to make use of functions across packages, we will explicitly state the origin each function by `package::function()`.

### tidyr

Let's take a look at the game by game player rushing and receiving statistics that we scraped using the principles outlined in the previous chapter. To do this, we will first use `stringr::str_c()`, a function we've seen a few times now, to create a web addresses corresponding to Pro Football Reference page for all of the 2020 NFL teams.

```{r}
pfr_url <- "https://www.pro-football-reference.com"
team_urls <- pfr_url %>%
  # get team abbreviations for all NFL teams and isolate Denver
  get_teams(.) %>%
  # create URLs for all 2020 NFL teams
  stringr::str_c(pfr_url, ., '2020.htm')
as_tibble(team_urls)
```

```{block, type ='bonus'}
Pipes (`%>%`) make your code much more readable and avoid unnecessary assignments. While not required in many cases, I use a period to indicate where the result to the left of the pipe belongs in the argument to the right of the pipe.
```

Now that we have the web addresses for every 2020 NFL team, let's isolate the 2020 Denver Broncos and scrape their players' aggregated rushing and receiving statistics. We will use `dplyr::glimpse()` to see the data types and a few values for each column in the data set. 

```{r}
den_stats <- team_urls %>%
  # isolate the 2020 Denver Bronco's URL
  .[10] %>%
  # get team statistics for 2020 Denver Broncos
  get_team_stats()
dplyr::glimpse(den_stats)
```

There are a few things to note after looking at the data, but let's first consider if these data are tidy. To answer this question, we need more context. If we wished to predict a player's position based on his statistics, then each player is an observation and his statistics are variables. In this case, these data are tidy in their current __wide__ form, when each player has information in only one row. If we are interested in comparing players across the recorded statistical categories, then an observation would no longer be a player but a player's statistical category. In this case, these data are tidy in __long__ form, when each player has information in multiple rows. No matter the context, `tidyr` makes it easy convert your data from wide form to long form with `tidyr::pivot_longer()` and from long form to wide form with `tidyr::pivot_wider()`.

```{r, fig.cap="visualizing the transformation from wide data to long data, and vice versa", echo=F, out.width='50%'}
knitr::include_graphics("src/images/widevlong.png")
```

Let's consider how we can use `tidyr::pivot_longer()` to tidy these data in preparation for comparing players across their statistical categories. In each row, we should expect to have (1) the player's name, age, and position, (2) the statistical category, and (3) the value of the statistical category. Imagine taking every other column and pushing them into the rows, duplicating the information above as needed. To do this in `R`, we will use the `dplyr` functions `dplyr::vars()` which allows us to select which variables to push into the rows and `dplyr::starts_with()` which allows us to pick only variables whose names start with some string. These are two handy functions to know. Further, we will use `tidyr::seperate` to split the statistical categories into a more general category (i.e. rushing, receiving, etc) and a statistic (i.e. yards per rushing attempt, catch percentage, etc).

```{r}
den_stats_long <- den_stats %>%
  # push columns into the rows, renaming the names and values columns
  pivot_longer(., cols = c(starts_with('games_'), starts_with('rushing_'),
                           starts_with('receiving_'), starts_with('yds_')),
               names_to = 'stat_category', values_to = 'value') %>%
  # seperate the stat category into a category column and a stat column
  separate(., col = 'stat_category', into = c('category', 'stat'), sep = '_', extra = 'merge')
den_stats_long
```

If we are in a situation when we are given a data set in long form, but we need it in wide form, we can use `tidyr::pivot_wider`.

```{r}
den_stats_wide <- den_stats_long %>%
  pivot_wider(., names_from = c('category', 'stat'), values_from = 'value')
den_stats_wide
```

After converting back to wide form, the result is the same as the original data set.

### dplyr

We've addressed how to change the shape of your data using `tidyr`. Now, we will transition into `dplyr` where we will outline some of the many functions that can prove helpful in preparing your data for plotting or modeling. Before we jump into various functions, let's outline the issues with our data set which have not been addressed. The best way to get a sense of the issues is to look at the data.

```{r}
den_stats
str(den_stats)
```

The first issue with the data set that we should address is the inappropriate data types assigned to each column. Every column is scraped as a character, but the players' position (pos) should be coded as a factor variable and the players' statistics should be coded as numeric variables. Before we can change the players' catch percentage (receiving_ctch_percent) to a numeric variable, we first need to remove the percent sign from the values of the variable. 

#### `mutate`

When we wish to change the values within a column, we can leverage the `dplyr::mutate()` function. Let's see how we can use some `stringr` functions within `dplyr::mutate()` to clean up some of these columns.

```{r}
den_stats_wking <- den_stats %>%
  mutate(., age = as.numeric(age),
         pos = pos %>% 
           str_to_upper() %>% 
           na_if(., '') %>% 
           as_factor(),
         receiving_ctch_percent = str_remove_all(receiving_ctch_percent, '%'))
den_stats_wking
```
Within one `mutate()` call, we (1) recoded the players' age as a numeric variable, (2) changed the players' position to uppercase, replaced empty strings with `NA` values, and recoded the result as a factor, and (3) removed all percent signs from the catch percent statistic. We still need to change all of the players' statistics to numeric variable. We could do this similarly to the players' age, but listing out every variable one by one would be painstakingly inefficient. To complete this task, we can use a common variant of the `mutate()` function called `mutate_at()` to change every specified column in a similar manner. We can then use `mutate_all()` to replace every missing string with an `NA` value, the proper way to specify a missing value in `R`.

```{r}
den_stats_wking <- den_stats_wking %>%
  mutate_at(., vars(starts_with('games_'), 
                    starts_with('rushing_'), 
                    starts_with('receiving_'), 
                    starts_with('yds_')), 
            ~as.numeric(.x)) %>%
  mutate_all(., ~na_if(.x, ''))
```

These variants of `mutate()` (e.g. `mutate_at` and `mutate_all`) are aimed to condense code when the same transformation is applied to many columns. To specify the transformation which will be applied to all of the identified columns, you will need a __lambda expression__. The lambda expressions start with `~` and are followed by a function specifying the transformation such as `as.numeric`. One of the arguments of the function will be `.x` which indicates an arbitrary column. To break down the `mutate_at()` specified above, we seek to transform all columns starting with `games_`, `rushing_`, `receiving_`, and `yds_`. Overall, there are `r den_stats %>% select(., starts_with('games_'), starts_with('rushing_'), starts_with('receiving_'), starts_with('yds_')) %>% ncol()` columns we will be transforming with this single mutate function. The lambda expression `~as.numeric(.x)` specifies how to transform each of these `r den_stats %>% select(., starts_with('games_'), starts_with('rushing_'), starts_with('receiving_'), starts_with('yds_')) %>% ncol()` columns. That is, for a given column called `.x`, change `.x` to be a numeric column. For more information on these variants, also known as __scoped verbs__ (e.g. `_if`, `_at`, `_all`), type `?mutate_if` into the console. Several functions we will discuss throughout this chapter also can be used with one of these scoped verbs.

#### `slice` and `filter`

Notice, at the bottom of the data set there are two rows which summarize the table. We do not need these rows since they do not outline the performance of an individual player. Keeping these rows would violate the principle of tidy data. There are two approaches we can take to remedy this issue. First, we could consider removing the last two rows of the data set or keeping all rows except for the last two. When we would like to remove or keep rows of a data set using the index of the row, we can leverage the `slice()` function. To illustrate how to do this, we will use a new helper function `n()` which returns the number of rows in the referenced data set.

```{r}
# option 1: remove the last two rows of the data set
den_stats_wking %>%
  slice(., -(n()-1), -n())
# or
den_stats_wking %>%
  slice(., -c(n()-1, n()))

# option 2: keep all rows except for the last two
den_stats_wking %>%
  slice(., 1:(n()-2))
```
While this certainly solves the issue for this particular data set, it is not a robust solution. If we hope to apply this same logic for other NFL teams, we need to recognize that this solution relies on there only being two total columns which take up the last two rows of the data set. A more robust solution would be to keep only rows consisting of a player not named `"Team Total"` or `"Opp Total"`. If we want to choose rows based on specific criteria, then we can utilize `filter()` to choose rows based on specific criteria.

```{r}
den_stats_wking <- den_stats_wking %>%
  filter(., !(player %in% c('Team Total', 'Opp Total')))
den_stats_wking
```

#### `select`

Suppose we're interested in only rushing and receiving statistics for each of the players.. In this case, we may wish to keep columns containing information on the players and the players' rushing and receiving statistics. If we want to keep certain columns based on the column names, then we can utilize the `select()` function. A verbose (but acceptable) solution would be to specify each column we want to keep. To demonstrate, I will keep only information pertaining to the player (e.g. jersey number, name, age, and position).

```{r}
den_stats_wking %>%
  select(., no, player, age, pos)
```

Since there are several variables for rushing and receiving statistics, we may not want to specify every column name we want to keep. Instead, we can use scoped verbs and helper functions, similar to `mutate()`.

```{r}
den_stats_wking <- den_stats_wking %>%
  select_at(., vars(team, no, player, age, pos, starts_with('rushing_'), starts_with('receiving_')))
```

#### `group_by`

Designed to be used with other functions, `group_by` groups rows of data set by an attribute. Suppose we're interested in positions rather than players. In this case, we would like to group players in common positions. When we invoke the `group_by` function, we are creating a tibble which looks a lot like the original but indicates which rows belong to which group.

```{r}
den_grouped <- den_stats_wking %>%
  group_by(., pos)

class(den_grouped)
group_vars(den_grouped)
```

Any functions invoked on grouped data will be conducted on the specified groups, rather than the data set as a whole. For example, suppose we're interested in determining the player with the most receptions by potion. We could utilize the helper `slice_max()` which will return the row with the largest value for the specified attribute. If we forgot to group the data set by position, then we would return the player with the most receptions, clearly a wide receiver. 

```{r}
den_stats_wking %>%
  slice_max(., receiving_rec)
```

If we group by position before invoking `slice_max` then we would return the players with the most receptions at each of the listed positions. When operating on grouped data, it is important to `ungroup` when we no longer want operations to be conducted on the groups.

```{r}
den_stats_wking %>%
  group_by(., pos) %>%
  slice_max(., receiving_rec) %>%
  ungroup(.)
```

```{block, type = 'reflect'}
If grouping data confuses you, don't worry! You are not alone. When using the `group_by` function, I like to imagine partitioning rows into literal groups and then asking myself what I would like to do with each of the groups. In this case, imagine the coach held a meeting on the field. To start the meeting, he asks all of his running backs (RB) to stand in the home end zone, his wide receivers to stand in the away end zone, and his tight ends (TE) to stand at the home sidelines. All of the other players (with unknown positions) are asked to stand at the away sidelines. In this sense, the coach has created four groups where each group consists of same positioned players. Now, the coach walks to each group individually and asks for the player with the most receptions to follow him. At the end of the day, each group sends one player, so the result is four players.

The `group_by` function is the coach asking his players to organize themselves on the field, and the `slice_max` function is asking the player with the largest number of receptions to follow him. Since the `slice_max` follows the `group_by` function, the coach for a player from each group.
```

#### `summarize`

The `summarize` function allows us to calculate summary statistics for specified columns. When paired with `group_by`, the `summarize` function allows us to calculate summary statistics for each of the groups. For example, suppose I wanted to calculate the average rushing and receiving yards, as well as standard deviations, for each of non-missing positions except for punter. Similar to the `mutate`, we can specify how we what we want the new columns to be called and how we want to define them.

```{r}
den_stats_wking %>%
  filter(., pos !='P', !is.na(pos)) %>%
  group_by(., pos) %>%
  summarize(., mean_rushing_yds = mean(rushing_yds),
            sd_rushing_yds = sd(rushing_yds),
            mean_receiving_yds = mean(receiving_yds),
            sd_receiving_yds = sd(receiving_yds))
```

## Functional Programming with `purrr`

In the previous subsection, we explored how to reshape and wrangle data with the `tidyr` and `dplyr` packages. We broke the functions up into sections for easier cross reference, but in reality, they can (and should) be combined together using pipes to avoid intermediate assignments. The following outlines all steps necessary to clean the rushing and receiving statistics for the 2020 Denver Broncos.

```{r}
"https://www.pro-football-reference.com/teams/den/2020.htm" %>%
  # scrape team stats
  get_team_stats(.) %>%
  # clean results of scrape
  mutate(., age = as.numeric(age),
         pos = pos %>% 
           str_to_upper() %>% 
           na_if(., '') %>% 
           as_factor(),
         receiving_ctch_percent = str_remove_all(receiving_ctch_percent, '%')) %>%
  mutate_at(., vars(starts_with('games_'), 
                    starts_with('rushing_'), 
                    starts_with('receiving_'), 
                    starts_with('yds_')), 
            ~as.numeric(.x)) %>%
  mutate_all(., ~na_if(.x, '')) %>%
  filter(., !(player %in% c('Team Total', 'Opp Total')), !is.na(pos), pos != 'P') %>%
  select_at(., vars(team, no, player, age, pos, 
                    starts_with('games_'),
                    starts_with('rushing_'), 
                    starts_with('receiving_')))
```

We've outlined how to get rushing and receiving statistics for the 2020 Denver Broncos, but now, we would like to attain the same statistics for every NFL team. Since Pro-Football Reference reports the same statistics for each team in the same manner,  we hope to scrape and clean each team's statistics using the code above, changing only the web address.

When we need to iterate over an object, we should reach for the `purrr` package which contains functions allowing us to `map` over different elements of a vector, data frame, or list. In our case, we have a vector of webpages, and for each webpage, we would like to scrape the rushing and receiving statistics before cleaning the result. First, we will use the `map` function to iterate over the vector of webpages. For each webpage, we will invoke `get_team_stats`. The result is a list of data frames where each element of the list corresponds to a specific team's scraped rushing and receiving statistics. The helper function `set_names` allows us to specify the name of each element of the resulting list. The lambda function `str_sub` extracts the three letter code in the team web address which specifies the team. 

```{r}
team_stats <- team_urls %>%
  # create list where each element is the result of the function get_team_stats
  # applied to the cooresponding 
  map(., ~get_team_stats(.x))

class(team_stats)

# print only the first three elements of the list
team_stats[1]
team_stats[2]
```

The first two elements of the resulting lists are the scraped rushing and receiving statistics for the 2020 Arizona Cardinals and the 2020 Atlanta Falcons. These data sets, along with the other thirty teams' statistics, need to be cleaned in the same manner as the 2020 Denver Broncos. While we originally used the `map` function to iterate over a vector of web addresses, we can also use it to iterate over the list of each team's scraped statistics, applying the same cleaning procedure to each element. Rather than use a lambda expression, we define a function. Lambda expressions are a convenient and concise way to specify a transformation if the transformation is defined by a single function. Previously, the entire act of scraping was described by one function: `get_team_stats()`. Since the cleaning procedure consists of multiple functions such as `mutate`, `filter`, and `select`, it is more convenient to specify the transformation in a function, rather than a lambda expression.

```{r}
team_stats_clean <- team_stats %>%
  # clean
  map(., function(x){
    x %>%
      mutate(., age = as.numeric(age),
             pos = pos %>% 
               str_to_upper() %>% 
               na_if(., '') %>% 
               as_factor(),
             receiving_ctch_percent = str_remove_all(receiving_ctch_percent, '%')) %>%
      mutate_at(., vars(starts_with('games_'), 
                        starts_with('rushing_'), 
                        starts_with('receiving_'), 
                        starts_with('yds_')), 
                ~as.numeric(.x)) %>%
      mutate_all(., ~na_if(.x, '')) %>%
      filter(., !(player %in% c('Team Total', 'Opp Total')), !is.na(pos), pos != 'P') %>%
      select_at(., vars(team, no, player, age, pos, 
                        starts_with('games_'),
                        starts_with('rushing_'), 
                        starts_with('receiving_')))
    }
  )
```

We can always rewrite functions within a `map` as a lambda expression if we first define the desired transformation as a function before calling the function as a lambda expression in the `map`.

```{r}
# define function with desired transfomation 
clean_team_stats <- function(x){
  x %>%
    mutate(., age = as.numeric(age),
           pos = pos %>% 
             str_to_upper() %>% 
             na_if(., '') %>% 
             as_factor(),
           receiving_ctch_percent = str_remove_all(receiving_ctch_percent, '%')) %>%
    mutate_at(., vars(starts_with('games_'), 
                      starts_with('rushing_'), 
                      starts_with('receiving_'), 
                      starts_with('yds_')), 
              ~as.numeric(.x)) %>%
    mutate_all(., ~na_if(.x, '')) %>%
    filter(., !(player %in% c('Team Total', 'Opp Total')), !is.na(pos), pos != 'P') %>%
    select_at(., vars(team, no, player, age, pos, 
                      starts_with('games_'),
                      starts_with('rushing_'), 
                      starts_with('receiving_')))
}

# map desired transformation to each team's scraped statistics using lambda
# expression
team_stats_clean_lambda <- team_stats %>%
  map(., ~clean_team_stats(.x))
  
# show results using funciton in map and lambda expression in map are the same
identical(team_stats_clean, team_stats_clean_lambda)
```

After mapping the cleaning procedure to each of the teams' scraped statistics, the result is a list where each element of the list is a tidy data frame consisting of a team's rushing and receiving statistics. As discussed in Chapter \@ref(AccessingData), we can rectangularize this list of data frames by binding the rows of each of these data frames, creating a column to indicate which team each row belongs.

```{r}
team_stats_clean %>%
  bind_rows(.)
```

Since the `purrr` package is a member of the Tidyverse, it is created with principles of Tidy data in mind. Transforming a list to a vector, or in our case, a data frame is often a common last step after mapping a function. To accommodate this need, the `purrr` package provides specific maps such as `map_dbl` and `map_chr` which transform the resulting list into a vector of type double or character, respectively. There is also `map_dfr` and `map_dfc` which binds the list elements together row-wise or column-wise, respectively, to return a data frame. If the result cannot be transformed into the requested type, an error will be returned. The mapping illustrated in this example can be written concisely as

```{r}
rush_receive <- team_urls %>%
  map(., ~get_team_stats(.x)) %>%
  map_dfr(., ~clean_team_stats(.x))
```

## Parallelization with `furrr`


When we `map` the function to scrape team statistics over the vector of team web addresses, we are insinuating that the function within the `map` (e.g. `get_team_stats`) should be applied to each element of the vector (e.g. `team_urls`) sequentially. Computational tasks which involve many separate, independently executable jobs should be run in __parallel__. When jobs are run in parallel, this means they are run at the same time, rather than sequentially. If the computational burden at each step is larger than the computational burden of setting up instructions for parallelization, then running code in parallel will save time.

While there are different types of parallelization, we will only focus on one: multi-core parallelization, which allows us to make use of the whole computer rather than rely on single processor architecture. `furrr`, a new Tidyverse package, attempts to make mapping in parallel easy and pain-free by combining the functionality of the `purrr` package and the `future` package. By combining `purrr`'s mapping capabilities and `future`'s parallel processing capabilities, `furrr` allows for parallelization with similar syntax.

In the previous subsection, we learned how to apply mapping functions to scrape and clean the statistics for each team, sequentially. Using `furrr`, we can parallelize this process. We will juxtapose each approach for comparison.

```{r}
# sequential computation using purrr
rush_receive_parallel <- team_urls %>%
  map(., ~get_team_stats(.x)) %>%
  map_dfr(., ~clean_team_stats(.x))

# parallel computation using furrr
library(furrr)
future::plan(multiprocess)

rush_receive_parallel <- team_urls %>%
  future_map(., ~get_team_stats(.x)) %>%
  future_map_dfr(., ~clean_team_stats(.x))

# compare output
identical(rush_receive, rush_receive_parallel)
```

Let's compare the speed of the operations.

```{r, cache=TRUE}
# sequentially
system.time(
  rush_receive <- team_urls %>%
    map(., ~get_team_stats(.x)) %>%
    map_dfr(., ~clean_team_stats(.x))
)

# parallel
system.time(
  rush_receive_parallel <- team_urls %>%
    future_map(., ~get_team_stats(.x)) %>%
    future_map_dfr(., ~clean_team_stats(.x))
)
```

We can see that parallelizing this process is about one and a half times faster than applying these functions sequentially. This effect is only amplified when we increase the number of sources to scrape. 

```{r, cache=TRUE}
player_urls <- team_urls %>% 
  map(., ~get_players(.x)) %>% 
  flatten_chr()

# sequentially
system.time(
  player_stats <- player_urls %>%
    map(., ~get_player_stats(.x))
)

# parallel
system.time(
  player_stats_par <- player_urls %>% 
    future_map(., ~get_player_stats(.x))
)
```

As we can see, parallelizing the scraping of all `r length(player_urls)` players who recorded rushing and receiving statistics in 2020 is about five times faster than scraping the same data sequentially.

## Scratch for Iterative Processes

In this case, the `map` function is sufficient since the scraped results for the Denver Broncos does not depend on the scraped results for the Dallas Cowboys. If the results of one iteration (e.g. the scraped results for the Denver Broncos) depended on the results of prior iterations (e.g. scraped results for the Dallas Cowboys), then the algorithm to scrape team statistics is __recursive__. When we have a recursive algorithm, the `map` function is often insufficient or overly complex. In this case, we may reach for a for-loop using the `for` function.

A for-loop allows us to repeat code multiple times making small changes with each iteration. To illustrate the concept of a for-loop, let's consider a famous example of a recursive algorithm: the Fibonacci sequence. The Fibonacci sequence is a sequence of integers starting with 0 and 1 where each following integer is the sum of the previous two integers. Written out, the first eight values of the Fibonacci sequence are $0, 1, 1, 2, 3, 5, 8, 13$. Let's consider how to use a for-loop to return the first $n$ integers in the Fibonacci sequence. Let's consider $n=8$ to start.

```{r}
n <- 8
fib_seq <- vector(mode = 'integer', length = n)
for(i in 1:n){
  # if it is the first element of the Fibonacci sequence, return a 0
  if(i == 1){
    fib_seq[i] <- 0
  }
  # if it is the second element of the Fibonacci sequence, return a 1
  else if(i == 2){
    fib_seq[i] <- 1
  }
  # if it is any other element of the Fibonacci sequence, return the sum of the 
  # previous two elements
  else{
    fib_seq[i] <- fib_seq[i-1] + fib_seq[i-2]
  }
}
fib_seq
```

Since each value of the Fibonacci sequence depends on the results of the prior two values of the Fibonacci sequence, a for-loop allows us to index the results of the sequence with each iteration. While intuitive, the for-loops can be very slow in `R`, especially when the recursive algorithm becomes more complex. In these situations, we need a faster alternative.