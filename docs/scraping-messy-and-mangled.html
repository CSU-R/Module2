<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>2.3 Scraping: Messy and Mangled | R Module 2</title>
  <meta name="description" content="This is the second installment for the book for the R Intro Course at CSU." />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="2.3 Scraping: Messy and Mangled | R Module 2" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is the second installment for the book for the R Intro Course at CSU." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2.3 Scraping: Messy and Mangled | R Module 2" />
  
  <meta name="twitter:description" content="This is the second installment for the book for the R Intro Course at CSU." />
  

<meta name="author" content="Connor Gibbs" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="APIs.html"/>
<link rel="next" href="Wrangling.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="libs/pagedtable-1.1/js/pagedtable.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="src\style.css" type="text/css" />
<link rel="stylesheet" href="src\environments.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">R Module 2</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Welcome!</a><ul>
<li class="chapter" data-level="1.0.1" data-path="index.html"><a href="index.html#how-to-navigate-this-book"><i class="fa fa-check"></i><b>1.0.1</b> How To Navigate This Book</a></li>
<li class="chapter" data-level="1.1" data-path="associated-csu-course.html"><a href="associated-csu-course.html"><i class="fa fa-check"></i><b>1.1</b> Associated CSU Course</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="AccessingData.html"><a href="AccessingData.html"><i class="fa fa-check"></i><b>2</b> Accessing Data</a><ul>
<li class="chapter" data-level="2.1" data-path="rectangular-vs-non-rectangular-data.html"><a href="rectangular-vs-non-rectangular-data.html"><i class="fa fa-check"></i><b>2.1</b> Rectangular vs. Non-rectangular Data</a><ul>
<li class="chapter" data-level="2.1.1" data-path="rectangular-vs-non-rectangular-data.html"><a href="rectangular-vs-non-rectangular-data.html#reading-and-writing-rectangular-data"><i class="fa fa-check"></i><b>2.1.1</b> Reading and Writing Rectangular Data</a></li>
<li class="chapter" data-level="2.1.2" data-path="rectangular-vs-non-rectangular-data.html"><a href="rectangular-vs-non-rectangular-data.html#reading-and-writing-non-rectangular-data"><i class="fa fa-check"></i><b>2.1.2</b> Reading and Writing Non-rectangular Data</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="APIs.html"><a href="APIs.html"><i class="fa fa-check"></i><b>2.2</b> APIs: Clean and Curated</a></li>
<li class="chapter" data-level="2.3" data-path="scraping-messy-and-mangled.html"><a href="scraping-messy-and-mangled.html"><i class="fa fa-check"></i><b>2.3</b> Scraping: Messy and Mangled</a><ul>
<li class="chapter" data-level="2.3.1" data-path="scraping-messy-and-mangled.html"><a href="scraping-messy-and-mangled.html#scraping-vs-apis"><i class="fa fa-check"></i><b>2.3.1</b> Scraping vs APIs</a></li>
<li class="chapter" data-level="2.3.2" data-path="scraping-messy-and-mangled.html"><a href="scraping-messy-and-mangled.html#LessonsLearnedFromScraping"><i class="fa fa-check"></i><b>2.3.2</b> Lessons Learned from Scraping</a></li>
<li class="chapter" data-level="2.3.3" data-path="scraping-messy-and-mangled.html"><a href="scraping-messy-and-mangled.html#tools-for-scraping"><i class="fa fa-check"></i><b>2.3.3</b> Tools for Scraping</a></li>
<li class="chapter" data-level="2.3.4" data-path="scraping-messy-and-mangled.html"><a href="scraping-messy-and-mangled.html#scraping-nfl-data"><i class="fa fa-check"></i><b>2.3.4</b> Scraping NFL Data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="Wrangling.html"><a href="Wrangling.html"><i class="fa fa-check"></i><b>3</b> Wrangling</a><ul>
<li class="chapter" data-level="3.1" data-path="core-tidyverse.html"><a href="core-tidyverse.html"><i class="fa fa-check"></i><b>3.1</b> Core Tidyverse</a><ul>
<li class="chapter" data-level="3.1.1" data-path="core-tidyverse.html"><a href="core-tidyverse.html#tidyr"><i class="fa fa-check"></i><b>3.1.1</b> tidyr</a></li>
<li class="chapter" data-level="3.1.2" data-path="core-tidyverse.html"><a href="core-tidyverse.html#dplyr"><i class="fa fa-check"></i><b>3.1.2</b> dplyr</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="functional-programming-with-purrr.html"><a href="functional-programming-with-purrr.html"><i class="fa fa-check"></i><b>3.2</b> Functional Programming with <code>purrr</code></a></li>
<li class="chapter" data-level="3.3" data-path="parallelization-with-furrr.html"><a href="parallelization-with-furrr.html"><i class="fa fa-check"></i><b>3.3</b> Parallelization with <code>furrr</code></a><ul>
<li class="chapter" data-level="3.3.1" data-path="parallelization-with-furrr.html"><a href="parallelization-with-furrr.html#scratch-for-iterative-processes"><i class="fa fa-check"></i><b>3.3.1</b> Scratch for Iterative Processes</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="supplemental.html"><a href="supplemental.html"><i class="fa fa-check"></i><b>4</b> Supplemental</a><ul>
<li class="chapter" data-level="4.1" data-path="scraping-in-the-wild.html"><a href="scraping-in-the-wild.html"><i class="fa fa-check"></i><b>4.1</b> Scraping in the Wild</a><ul>
<li class="chapter" data-level="4.1.1" data-path="scraping-in-the-wild.html"><a href="scraping-in-the-wild.html#LessonsLearned"><i class="fa fa-check"></i><b>4.1.1</b> Lessons Learned from Scraping</a></li>
<li class="chapter" data-level="4.1.2" data-path="scraping-in-the-wild.html"><a href="scraping-in-the-wild.html#scraping-nfl-data-1"><i class="fa fa-check"></i><b>4.1.2</b> Scraping NFL Data</a></li>
<li class="chapter" data-level="4.1.3" data-path="scraping-in-the-wild.html"><a href="scraping-in-the-wild.html#putting-it-all-together"><i class="fa fa-check"></i><b>4.1.3</b> Putting It All Together</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">R Module 2</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="scraping-messy-and-mangled" class="section level2">
<h2><span class="header-section-number">2.3</span> Scraping: Messy and Mangled</h2>
<p>If you are reading this textbook, at some point in your career, you are likely to want or need data which exists on the web. You have looked for downloadable sources and Google searched for an API, but alas, no luck. The last resort for importing data into <code>R</code> is <strong>web scraping</strong>. Web scraping is a technique for harvesting data which is portrayed on the web and exists in hypertext markup language (HTML), the language of web browser documents.</p>
<div id="scraping-vs-apis" class="section level3">
<h3><span class="header-section-number">2.3.1</span> Scraping vs APIs</h3>
<p>The benefit of using an API are clean data. For example, we can traverse the result to find the latest NFL events.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r chunk-style"><code class="sourceCode r"><a class="sourceLine" id="cb14-1" title="1"><span class="kw">head</span>(bov_res[[<span class="dv">2</span>]][[<span class="dv">1</span>]][,<span class="dv">2</span>])</a></code></pre></div>
<pre class="output-style"><code>[1] &quot;Tampa Bay Buccaneers @ New York Giants&quot;
[2] &quot;Carolina Panthers @ Kansas City Chiefs&quot;
[3] &quot;Chicago Bears @ Tennessee Titans&quot;      
[4] &quot;Denver Broncos @ Atlanta Falcons&quot;      
[5] &quot;Detroit Lions @ Minnesota Vikings&quot;     
[6] &quot;Houston Texans @ Jacksonville Jaguars&quot; </code></pre>
<p>With more digging, we can find which teams are playing at home.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r chunk-style"><code class="sourceCode r"><a class="sourceLine" id="cb16-1" title="1"><span class="kw">head</span>(bov_res[[<span class="dv">2</span>]][[<span class="dv">1</span>]][[<span class="dv">16</span>]])</a></code></pre></div>
<pre class="output-style"><code>[[1]]
                id                 name  home
1 7834332-11904218      New York Giants  TRUE
2 7834332-11904225 Tampa Bay Buccaneers FALSE

[[2]]
                id               name  home
1 7861881-11852811 Kansas City Chiefs  TRUE
2 7861881-11904216  Carolina Panthers FALSE

[[3]]
                id             name  home
1 7863412-11904229 Tennessee Titans  TRUE
2 7863412-11903832    Chicago Bears FALSE

[[4]]
                id            name  home
1 7863382-11904242 Atlanta Falcons  TRUE
2 7863382-11904245  Denver Broncos FALSE

[[5]]
                id              name  home
1 7863406-11904246 Minnesota Vikings  TRUE
2 7863406-11904244     Detroit Lions FALSE

[[6]]
                id                 name  home
1 7863366-11904220 Jacksonville Jaguars  TRUE
2 7863366-11904230       Houston Texans FALSE</code></pre>
<p>We can also find the current line of each of these games. Here, I have created a function called <code>get_bovada_lines()</code> which traverses this complicated (yet clean) JSON object using methods explored in Chapter 3 and combines the information together into a rectangular data set.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r chunk-style"><code class="sourceCode r"><a class="sourceLine" id="cb18-1" title="1">bov_res <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb18-2" title="2"><span class="st">  </span><span class="kw">get_bovada_lines</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb18-3" title="3"><span class="st">  </span><span class="kw">print</span>(<span class="dt">n =</span> <span class="dv">10</span>)</a></code></pre></div>
<pre class="output-style"><code># A tibble: 16 x 16
   id    link  description startTime           live  type  lastModified       
   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;       &lt;dttm&gt;              &lt;lgl&gt; &lt;chr&gt; &lt;dttm&gt;             
 1 7834~ /foo~ Tampa Bay ~ 2020-11-02 18:15:00 FALSE GAME~ 2020-11-02 15:10:37
 2 7834~ /foo~ Tampa Bay ~ 2020-11-02 18:15:00 FALSE GAME~ 2020-11-02 15:10:37
 3 7861~ /foo~ Carolina P~ 2020-11-08 11:00:00 FALSE GAME~ 2020-11-02 15:05:18
 4 7861~ /foo~ Carolina P~ 2020-11-08 11:00:00 FALSE GAME~ 2020-11-02 15:05:18
 5 7863~ /foo~ Chicago Be~ 2020-11-08 11:00:00 FALSE GAME~ 2020-11-02 15:12:52
 6 7863~ /foo~ Chicago Be~ 2020-11-08 11:00:00 FALSE GAME~ 2020-11-02 15:12:52
 7 7863~ /foo~ Denver Bro~ 2020-11-08 11:00:00 FALSE GAME~ 2020-11-02 15:01:38
 8 7863~ /foo~ Denver Bro~ 2020-11-08 11:00:00 FALSE GAME~ 2020-11-02 15:01:38
 9 7863~ /foo~ Detroit Li~ 2020-11-08 11:00:00 FALSE GAME~ 2020-11-02 15:05:18
10 7863~ /foo~ Detroit Li~ 2020-11-08 11:00:00 FALSE GAME~ 2020-11-02 15:05:18
# ... with 6 more rows, and 9 more variables: team_id &lt;chr&gt;, name &lt;chr&gt;,
#   home &lt;lgl&gt;, juice_money &lt;dbl&gt;, handicap_spread &lt;dbl&gt;, juice_spread &lt;dbl&gt;,
#   handicap_total &lt;dbl&gt;, juice_over &lt;dbl&gt;, juice_under &lt;dbl&gt;</code></pre>
<p>While traversing these sometimes complicated lists may seem intimidating, with practice, working with data from an API will be made easier after discussing mapping functions in Chapter 3 which are useful for traversing complicated lists. Hopefully, after the scraping section, you will find working with APIs like a walk in the park compared to scraping data directly from the web.</p>
</div>
<div id="LessonsLearnedFromScraping" class="section level3">
<h3><span class="header-section-number">2.3.2</span> Lessons Learned from Scraping</h3>
<p>Scraping is a necessary evil that requires patience. While some tasks may prove easy, you will quickly find others seem insurmountable. In this section, we will outline a few tips to help you become a web scraper.</p>
<ol style="list-style-type: decimal">
<li><p><strong>Brainstorm</strong>! Before jumping into your scraping project, ask yourself <em>what data do I need</em> and <em>where can I find it</em>? If you discover you need data from various sources, <em>what is the unique identifier</em>, the link which ties these data together? Taking the time to explore different websites can save you a vast amount of time in the long run. As a general rule, simplistic looking websites are generally easier to scrape and often contain the same information as more complicated websites with several bells and whistles.</p></li>
<li><p><strong>Start small</strong>! Sometimes a scraping task can feel daunting, but it is important to <em>view your project as a war, splitting it up into small battles</em>. If you are interested in the racial demographics of each of the United States, consider how you can first scrape this information for one state. In this process, don’t forget tip 1!</p></li>
<li><p><strong>Hyperlinks are your friend</strong>! They can lead to websites with more detailed information or serve as the unique identifier you need between different data sources. Sometimes you won’t even need to scrape the hyperlinks to navigate between webpages, making minor adjustments to the web address will sometimes do.</p></li>
<li><p><strong>Data is everywhere</strong>! Text color, font, or highlighting may serve as valuable data that you need. If these features exist on the webpage, then they exist within the HTML code which generated the document. Sometimes these features are well hidden or even inaccessible, leading to the last and final tip.</p></li>
<li><p><strong>Ready your search engine</strong>! Just like coding in <code>R</code> is an art, web developing is an art. When asking distinct developers to create the same website with the same functionality, the final result may be similar but the underlying HTML code could be drastically different. Why does this matter? You will run into an issue that hasn’t been addressed in this text. Thankfully, if you’ve run into an issue, someone else probably has too. We cannot recommend websites like <a href="https://stackoverflow.com/">Stack Overflow</a> enough.</p></li>
</ol>
</div>
<div id="tools-for-scraping" class="section level3">
<h3><span class="header-section-number">2.3.3</span> Tools for Scraping</h3>
<p>Before we can scrape information from a webpage, we need a bit of background on how this information is stored and presented. The goal of this subsection is to briefly introduce the languange of the web, hypertext markup language (HTML). When we talk about scraping the web, what we really mean is gathering bits of information from the HTML code used to build a webpage. Like <code>R</code> code, HTML can be overwhelming. The goal is not to teach HTML but to introduce its components, so you have a much more intuitive sense of what we are doing when we scrape the web.</p>
<div id="hypertext-markup-language-html" class="section level4">
<h4><span class="header-section-number">2.3.3.1</span> Hypertext Markup Language (HTML)</h4>
<p>Web sites are written in hypertext markup language. All contents that are displayed on a web page are structured through HTML with the help of HTML <strong>elements</strong>. HTML elements consist of a tag and contents. The <strong>tag</strong> defines how the web browser should format and display the content. Aptly, the <strong>content</strong> is what should be displayed.</p>
<p>For example, if we wished to format text as a paragraph within the web document, then we could use the paragraph tag, <code>&lt;p&gt;</code>, to indicate the beginning of a paragraph. After opening a tag, we then specify the content to display before closing the tag. A complete paragraph may read:</p>
<p><code>&lt;p&gt; This is the paragraph you want to scrape. &lt;/p&gt;</code></p>
<p><strong>Attributes</strong> are optional parameters which provide additional information about the element in which the attribute is included. For example, within the paragraph tag, you can define a class attribute which formats the text in a specific way, such as bolding, coloring, or aligning the text. To extend our example, the element may read:</p>
<p><code>&lt;p class = "fancy"&gt; This is the paragraph you want to scrape which has been formatted in a fancy script. &lt;/p&gt;</code></p>
<p>The type of attribute, being class, is the attribute <strong>name</strong>, whereas the quantity assigned to the attribute, being fancy, is the attribute <strong>value</strong>. The general decomposition of an HTML element is characterized by the following figure:</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-24"></span>
<img src="src/images/element_decomp.jpg" alt="the lingo of an HTML element" width="442" />
<p class="caption">
Figure 2.1: the lingo of an HTML element
</p>
</div>
<div class="bonus">
<p>
The class attribute is a flexible one. Many web developers use the class attribute to point to a class name in a style sheet or to access and manipulate elements with the specific class name with a JavaScript. For more information of the class attribute, see this <a href="https://www.w3schools.com/html/html_classes.asp">link</a>. For more information on cascading style sheets which are used to decorate HTML pages, see this <a href="https://www.w3schools.com/css/">link</a>.
</p>
</div>
<div class="feedback">
<p>
Any feedback for this section? Click <a href="https://docs.google.com/forms/d/e/1FAIpQLSePQZ3lIaCIPo9J2owXImHZ_9wBEgTo21A0s-A1ty28u4yfvw/viewform?entry.1684471501=The%20R%20Community">here</a>
</p>
</div>
</div>
<div id="selector-gadgets" class="section level4">
<h4><span class="header-section-number">2.3.3.2</span> Selector Gadgets</h4>
<p>While all web pages are composed of HTML elements, the elements themselves can be structured in complicated ways. Elements are often nested inside one another or make use of elements in other documents. These complicated structures can make scraping data difficult. Thankfully, we can circumvent exploring these complicated structures with the help of selector gadgets.</p>
<p>A <strong>selector gadget</strong> allows you to determine what css selector you need to extract the information desired from a webpage. These JavaScript bookmarklets allow you to determine where the information you desire belongs within the complicated structure of elements that makeup a webpage. To follow along in Chapter 3, you will need to download one of these gadgets from this <a href="https://selectorgadget.com/">link</a>. If you use Google Chrome, you can download the bookmark extension directly from this <a href="https://selectorgadget.com/">link</a>.</p>
<p>If the selector gadget fails us, we can always view the structure of the elements directly by viewing the page source. This can be done by right-clicking on the webpage and selecting ‘View Page Source’. For Google Chrome, you can also use the keyboard shortcut ‘CTRL-U’.</p>
</div>
</div>
<div id="scraping-nfl-data" class="section level3">
<h3><span class="header-section-number">2.3.4</span> Scraping NFL Data</h3>
<p>In Chapter <a href="APIs.html#APIs">2.2</a>, we gathered some betting data pertaining to the NFL through a web-API. We may wish to supplement these betting data with data pertaining to NFL teams, players, or even playing conditions. The goal in this subsection is to introduce you to scraping by heeding the advice given in the Chapter <a href="scraping-messy-and-mangled.html#LessonsLearnedFromScraping">2.3.2</a>. Further examples are given in the supplemental material.</p>
<p>Following our own advice, let’s brainstorm. When you think of NFL data, you probably think of <a href="https://www.nfl.com/stats">NFL.com</a> or <a href="https://www.espn.com/nfl/stats">ESPN</a>. These sites obviously have reliable data, but the webpages are pretty involved. While the filters, dropdown menus, and graphics lend great experiences for web browsers, they create headaches for web scrapers. After further digging, we will explore <a href="https://www.pro-football-reference.com/">Pro Football Reference</a>, a reliable archive for football statistics (with a reasonably simple webpage). This is an exhaustive source which boasts team statistics, player statistics, and playing conditions for various seasons. Let’s now start small by focusing on team statistics, but further, let’s limit our scope to the <a href="https://www.pro-football-reference.com/teams/den/2020.htm">2020 Denver Broncos</a>. Notice, there are hyperlinks for each <a href="https://www.pro-football-reference.com/players/G/GordMe00.htm">player</a> documented in any of the categories, as well hyperlinks for each game’s <a href="https://www.pro-football-reference.com/boxscores/202009140den.htm">boxscore</a> where there is information about playing conditions and outcomes. Hence, we have a common thread between team statistics, players, and boxscores. If, for example, we chose to scrape team statistics from one website and player statistics from another website, we may have to worry about a unique identifier (being team) if the websites have different naming conventions.</p>
<div id="html-tables-team-statistics" class="section level4">
<h4><span class="header-section-number">2.3.4.1</span> HTML Tables: Team Statistics</h4>
<p>We’ll start with the team statistics for the 2020 Denver Broncos which can be found in a table entitled ‘Team Stats and Rankings’. We’ll need to figure in which element or <strong>node</strong> the table lives within the underlying HTML. To do this, we will utilize the CSS selector gadget. If we highlight over and click the table with the selector gadget, we will see that the desired table lives in an element called ‘#team_stats’.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-27"></span>
<img src="src/images/broncos_selector_gadget.png" alt="finding the team statistics element using the selector gadget" width="800" />
<p class="caption">
Figure 2.2: finding the team statistics element using the selector gadget
</p>
</div>
<p>Alternatively, we could view the page source and search for the table name. I’ve highlighted the information identified by the selector gadget with the cursor.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-28"></span>
<img src="src/images/broncos_page_source.png" alt="finding the team statistics element using the page source" width="800" />
<p class="caption">
Figure 2.3: finding the team statistics element using the page source
</p>
</div>
<div class="caution">
<p>
While the selector gadget is always a great first option, it is not always reliable. There are instances when the selector gadget identifies a node that is hidden or inaccessible without JavaScript. In these situations, it is best view the page source directly for more guidance on how to proceed. Practice with both the selector gadget and the page source.
</p>
</div>
<p>Once we have found the name of the element containing the desired data, we can utilize the <code>rvest</code> package to scrape the table. The general process for scraping an HTML table is</p>
<ol style="list-style-type: decimal">
<li>Read the HTML identified by the web address.</li>
<li>Isolate the node containing the data we desire.</li>
<li>Parse the HTML table.</li>
<li>Take a look at the data to ensure the columns are appropriate labels.</li>
</ol>
<div class="sourceCode" id="cb20"><pre class="sourceCode r chunk-style"><code class="sourceCode r"><a class="sourceLine" id="cb20-1" title="1"><span class="kw">library</span>(rvest)</a>
<a class="sourceLine" id="cb20-2" title="2"><span class="kw">library</span>(janitor)</a>
<a class="sourceLine" id="cb20-3" title="3"></a>
<a class="sourceLine" id="cb20-4" title="4">pfr_url &lt;-<span class="st"> &quot;https://www.pro-football-reference.com&quot;</span></a>
<a class="sourceLine" id="cb20-5" title="5">broncos_url &lt;-<span class="st"> </span><span class="kw">str_c</span>(pfr_url, <span class="st">&#39;/teams/den/2020.htm&#39;</span>)</a>
<a class="sourceLine" id="cb20-6" title="6"></a>
<a class="sourceLine" id="cb20-7" title="7">broncos_url <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb20-8" title="8"><span class="st">  </span><span class="co"># read the HTML</span></a>
<a class="sourceLine" id="cb20-9" title="9"><span class="st">  </span><span class="kw">read_html</span>(.) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb20-10" title="10"><span class="st">  </span><span class="co"># isolate the node containing the HTML table</span></a>
<a class="sourceLine" id="cb20-11" title="11"><span class="st">  </span><span class="kw">html_node</span>(., <span class="dt">css =</span> <span class="st">&#39;#team_conversions&#39;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb20-12" title="12"><span class="st">  </span><span class="co"># parse the html table</span></a>
<a class="sourceLine" id="cb20-13" title="13"><span class="st">  </span><span class="kw">html_table</span>(.) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb20-14" title="14"><span class="st">  </span><span class="co"># make the first row of the table column headers and clean up column names</span></a>
<a class="sourceLine" id="cb20-15" title="15"><span class="st">  </span><span class="kw">row_to_names</span>(., <span class="dt">row_number =</span> <span class="dv">1</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb20-16" title="16"><span class="st">  </span><span class="kw">clean_names</span>()</a></code></pre></div>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["player"],"name":[1],"type":["chr"],"align":["left"]},{"label":["x3d_att"],"name":[2],"type":["chr"],"align":["left"]},{"label":["x3d_conv"],"name":[3],"type":["chr"],"align":["left"]},{"label":["x3d_percent"],"name":[4],"type":["chr"],"align":["left"]},{"label":["x4d_att"],"name":[5],"type":["chr"],"align":["left"]},{"label":["x4d_conv"],"name":[6],"type":["chr"],"align":["left"]},{"label":["x4d_percent"],"name":[7],"type":["chr"],"align":["left"]},{"label":["rz_att"],"name":[8],"type":["chr"],"align":["left"]},{"label":["rztd"],"name":[9],"type":["chr"],"align":["left"]},{"label":["rz_pct"],"name":[10],"type":["chr"],"align":["left"]}],"data":[{"1":"Team Stats","2":"91","3":"33","4":"36.3","5":"6","6":"0","7":"0.0","8":"20","9":"10","10":"50.0","_rn_":"2"},{"1":"Opp. Stats","2":"100","3":"36","4":"36.0","5":"9","6":"4","7":"44.4","8":"25","9":"12","10":"48.0","_rn_":"3"},{"1":"Lg Rank Offense","2":"","3":"","4":"30","5":"","6":"","7":"32","8":"","9":"","10":"29","_rn_":"4"},{"1":"Lg Rank Defense","2":"","3":"","4":"6","5":"","6":"","7":"10","8":"","9":"","10":"3","_rn_":"5"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>While these data need cleaning up before they can be used in practice, we will defer these responsibilities to Chapter <a href="Wrangling.html#Wrangling">3</a>.</p>
<div class="progress">
<p>
Take this time to scrape the ‘Team Conversions’ table on your own.
</p>
</div>
<div class="caution">
<p>
While it is exciting to scrape your first nuggets of data, we have just scratched the surface of web scraping. To be honest, it took some time to find data this easy to scrape. More often than not, difficulties arise. The HTML table you want may be commented out or hidden. Your data may not be in the form of a table, at all. For a more in-depth exposition of web scraping, see the supplemental materials.
</p>
</div>
<div class="feedback">
<p>
Any feedback for this section? Click <a href="https://docs.google.com/forms/d/e/1FAIpQLSePQZ3lIaCIPo9J2owXImHZ_9wBEgTo21A0s-A1ty28u4yfvw/viewform?entry.1684471501=The%20R%20Community">here</a>
</p>
</div>

</div>
</div>
</div>
<!-- </div> -->
            </section>

          </div>
        </div>
      </div>
<a href="APIs.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="Wrangling.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Module2.pdf", "Module2.epub"],
"toc": {
"collapse": "subsection"
},
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
